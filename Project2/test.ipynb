{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    cwd = os.getcwd()  #getting the path of this current program\n",
    "    filename = cwd + '/default of credit card clients.xls'  #path + file\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    #Read file into pandas dataframe \n",
    "    nanDict= {}\n",
    "    df = pd.read_excel('default of credit card clients.xls', header=1, skiprows=0, index_col=0, na_values=nanDict)\n",
    "    df.rename(index=str, columns={'default payment next month': 'defaultPaymentNextMonth'}, inplace=True)\n",
    "\n",
    "    #Drop the rows including data where parameters are out of range\n",
    "    df=df.drop(df[df.SEX<1].index)\n",
    "    df=df.drop(df[df.SEX<2].index)\n",
    "    df=df.drop(df[(df.EDUCATION <1)].index)\n",
    "    df=df.drop(df[(df.EDUCATION >4)].index)\n",
    "    df=df.drop(df[df.MARRIAGE<1].index)\n",
    "    df=df.drop(df[df.MARRIAGE>3].index)\n",
    "\n",
    "\n",
    "    #Features and targets\n",
    "    #.values returns a numpy representation of the DataFrame\n",
    "    X= df.loc[:, df.columns != 'defaultPaymentNextMonth'].values \n",
    "    y= df.loc[:, df.columns == 'defaultPaymentNextMonth'].values\n",
    "    \n",
    "    # Categorical variables to one-hot's\n",
    "    onehotencoder = OneHotEncoder(categories=\"auto\")\n",
    "\n",
    "    #OneHot encoder for column 1,2,3,5,6,7,8,9,10 [sex,education,marriage, pay_april, pay_may, pay_jun, pay_jul, pay_aug, pay_sep]\n",
    "    #Designmatrix, hotencoder on the categorical columns\n",
    "    X = ColumnTransformer(\n",
    "    [('onehotencoder', onehotencoder, [1,2,3,5,6,7,8,9,10]),],\n",
    "    remainder=\"passthrough\").fit_transform(X)\n",
    "\n",
    "    return X, np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test= np.where(X[:,1]<1, X[:,1], X[:,1] >2)[0]\n",
    "#test\n",
    "X= df.loc[:, df.columns != 'defaultPaymentNextMonth'].values\n",
    "y= df.loc[:, df.columns == 'defaultPaymentNextMonth'].values\n",
    "\n",
    "\n",
    "outlier_gender1 = np.where(X[:,1] < 1)[0]\n",
    "outlier_gender2 = np.where(X[:,1] > 2)[0]\n",
    "\n",
    "outlier_education1 = np.where(X[:,2] < 1)[0]\n",
    "outlier_education2 = np.where(X[:,2] > 4)[0]\n",
    "\n",
    "outlier_marital1 = np.where(X[:,3] < 1)[0]\n",
    "outlier_marital2 = np.where(X[:,3] > 3)[0]\n",
    "\n",
    "inds = np.concatenate((outlier_gender1,\n",
    "                        outlier_gender2,\n",
    "                        outlier_education1,\n",
    "                        outlier_education2,\n",
    "                        outlier_marital1,\n",
    "                        outlier_marital2))\n",
    "\n",
    "outlier_rows = np.unique(inds)\n",
    "X = np.delete(X, outlier_rows, axis=0)\n",
    "y = np.delete(y, outlier_rows, axis=0)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "trainingShare = 0.5 \n",
    "seed  = 1\n",
    "XTrain, XTest, yTrain, yTest=train_test_split(X, y, train_size=trainingShare,\n",
    "                                              test_size = 1-trainingShare,\n",
    "                                              random_state=seed)\n",
    "\n",
    "# Input Scaling\n",
    "sc = StandardScaler()\n",
    "XTrain = sc.fit_transform(XTrain)\n",
    "XTest = sc.transform(XTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot's of the target vector\n",
    "Y_train_onehot, Y_test_onehot = onehotencoder.fit_transform(yTrain), onehotencoder.fit_transform(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lambdas=np.logspace(-5,7,13)\n",
    "parameters = [{'C': 1./lambdas, \"solver\":[\"lbfgs\"]}]#*len(parameters)}]\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "logReg = LogisticRegression()\n",
    "gridSearch = GridSearchCV(logReg, parameters, cv=5, scoring=scoring, refit='roc_auc')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idunnmoatue/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/idunnmoatue/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.80\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      4284\n",
      "           1       0.00      0.00      0.00      1073\n",
      "\n",
      "    accuracy                           0.80      5357\n",
      "   macro avg       0.40      0.50      0.44      5357\n",
      "weighted avg       0.64      0.80      0.71      5357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Testing full code for Neural Network, based on lecture notes 'Data Analysis and Machine Learning: Neural networks, from the simple perceptron to deep learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, X, y, n_hidden_neurons=50 , n_categories=10 , epochs=100 , batch_size=100 , eta=0.1 , lmbd=0.0):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_full = self.X\n",
    "        self.y_full = self.y\n",
    "        \n",
    "        self.n_inputs         = X.shape[0]  #X-rows\n",
    "        self.n_features       = X.shape[1]  #X-columns \n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.n_categories     = n_categories\n",
    "        \n",
    "        self.epochs           = epochs\n",
    "        self.batch_size       = batch_size\n",
    "        self.iterations       = self.n_inputs // self.batch_size #Floor division\n",
    "        self.eta              = eta\n",
    "        self.lmbd             = lmbd\n",
    "        \n",
    "        self.create_biases_and_weights() #gives the initial bias and weigths. \n",
    "        self.feed_forward()\n",
    "        #print(self.hidden_weights)\n",
    "        #print(\"***\")\n",
    "        self.backpropagation()\n",
    "        #print(self.hidden_weights)        \n",
    "            \n",
    "    def sigmoid(self,x):\n",
    "        return(1/(1 + np.exp(-x)))\n",
    "        \n",
    "    def create_biases_and_weights(self):\n",
    "        self.hidden_weights = np.random.randn(self.n_features, self.n_hidden_neurons)\n",
    "        self.hidden_bias    = np.zeros(self.n_hidden_neurons) + 0.01\n",
    "        self.output_weights = np.random.randn(self.n_hidden_neurons, self.n_categories)\n",
    "        self.output_bias    = np.zeros(self.n_categories) + 0.01\n",
    "    \n",
    "    def feed_forward(self):\n",
    "        #feed_forward training\n",
    "        self.z_h = np.matmul(self.X, self.hidden_weights) + self.hidden_bias\n",
    "        self.a_h = self.sigmoid(self.z_h)\n",
    "        \n",
    "        self.z_o = np.matmul(self.a_h, self.output_weights) + self.output_bias\n",
    "        \n",
    "        exp_term = np.exp(self.z_o)\n",
    "        self.probabilities = exp_term /np.sum(exp_term, axis=1, keepdims=True)\n",
    "        \n",
    "    \n",
    "    def feed_forward_output(self, X):\n",
    "        #feed_forward for output\n",
    "        z_h = np.matmul(X, self.hidden_weights) + self.hidden_bias\n",
    "        a_h = self.sigmoid(z_h)\n",
    "        \n",
    "        z_o = np.matmul(a_h, self.output_weights) + self.output_bias\n",
    "\n",
    "        exp_term = np.exp(z_o)\n",
    "        probabilities = exp_term/ np.sum(exp_term, axis=1, keepdims=True)\n",
    "        return probabilities\n",
    "    \n",
    "    def backpropagation(self):\n",
    "   \n",
    "        error_output = self.probabilities - self.y  #cost function\n",
    "        error_hidden = np.matmul(error_output, self.output_weights.T) *self.a_h * (1-self.a_h)\n",
    "        \n",
    "        self.output_weights_gradient = np.matmul(self.a_h.T, error_output)\n",
    "        self.output_bias_gradient    = np.sum(error_output, axis=0)\n",
    "        \n",
    "        self.hidden_weights_gradient = np.matmul(self.X.T, error_hidden)\n",
    "        self.hidden_bias_gradient    = np.sum(error_hidden, axis=0)\n",
    "        \n",
    "        \n",
    "        if self.lmbd > 0.0:\n",
    "            self.output_weights_gradient += self.lmbd * self.output_weights\n",
    "            self.hidden_weights_gradient += self.lmbd * self.hidden_weights\n",
    "            \n",
    "        self.output_weights -= self.eta * self.output_weights_gradient\n",
    "        self.output_bias    -= self.eta * self.output_bias_gradient\n",
    "        self.hidden_weights -= self.eta * self.hidden_weights_gradient\n",
    "        self.hidden_bias    -= self.eta * self.hidden_bias_gradient \n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        probabilities = self.feed_forward_out(X)\n",
    "        return np.argmax(probabilities, axis = 1)\n",
    "    \n",
    "    def predict_probabilities(self, X):\n",
    "        probabilities = self.feed_forward_output(X)\n",
    "        return probabilities\n",
    "    \n",
    "    def train(self):\n",
    "        data_ind = np.arange(self.n_inputs)\n",
    "        print(\"hellu\")\n",
    "        for i in range(self.epochs):\n",
    "            for j in range(self.iterations):\n",
    "                #pick datapoints with replacements\n",
    "                chosen_datapoints = np.random.choice(data_ind, size=self.batch_size, replace=False)\n",
    "                \n",
    "                #minibatch training data\n",
    "                self.X_full = self.X[chosen_datapoints]\n",
    "                self.y_full = self.y[chosen_datapoints]\n",
    "                \n",
    "                self.feed_forward()\n",
    "                self.backpropagation()\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "          \n",
    "  \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork( X, y, n_hidden_neurons=50, n_categories=10 , epochs=100 , batch_size=100 , eta=0.1 , lmbd=0.0)\n",
    "\n",
    "NN.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
